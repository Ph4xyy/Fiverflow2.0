/**
 * Edge Function Supabase pour l'assistant AI
 * Appelle OpenAI de mani√®re s√©curis√©e depuis le serveur
 */

import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const OPENAI_API_KEY = Deno.env.get('OPENAI_API_KEY');
const OPENAI_MODEL = 'gpt-3.5-turbo'; // Mod√®le plus accessible et moins co√ªteux

interface LLMMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

// Headers CORS pour permettre les requ√™tes depuis le client
const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
  'Access-Control-Allow-Methods': 'POST, OPTIONS',
};

serve(async (req) => {
  // G√©rer la requ√™te preflight OPTIONS pour CORS
  if (req.method === 'OPTIONS') {
    return new Response(null, {
      status: 200,
      headers: corsHeaders
    });
  }

  try {
    const { message, conversationHistory = [] } = await req.json();

    if (!message) {
      return new Response(
        JSON.stringify({ error: 'Message requis' }),
        { 
          status: 400, 
          headers: {
            ...corsHeaders,
            'Content-Type': 'application/json'
          }
        }
      );
    }

    if (!OPENAI_API_KEY) {
      return new Response(
        JSON.stringify({ error: 'OPENAI_API_KEY non configur√©e' }),
        { 
          status: 500, 
          headers: {
            ...corsHeaders,
            'Content-Type': 'application/json'
          }
        }
      );
    }

    // System prompt pour l'assistant
    const systemPrompt = `
Tu es Jett ‚Äî l'assistant AI de FiverFlow. Ton nom est Jett.

Parle de fa√ßon naturelle, comme un humain normal. Pas comme un bot de support client, mais comme un ami intelligent et sympa avec qui on discute.

IMPORTANT - R√àGLES D'OR :
- Ne r√©p√®te JAMAIS "Comment puis-je t'aider ?" ou "How can I help you?" √† moins que ce soit vraiment pertinent
- Ne te r√©introduis pas ("Je m'appelle Jett") sauf si on te le demande explicitement
- R√©ponds DIRECTEMENT aux questions. Si on demande "√ßa va ?", r√©ponds vraiment "√áa va bien, merci ! Et toi ?" ‚Äî pas "Je suis l√† pour t'aider"
- Si la conversation est sociale/casual, r√©ponds comme une personne normale ferait
- Engage-toi dans la conversation. Sois pr√©sent, r√©agis, pose des questions de suivi naturelles

PERSONNALIT√â :
- Amical, d√©tendu, intelligent
- Tu peux plaisanter un peu, faire des blagues l√©g√®res
- Utilise des emojis naturellement (üòä üòÑ üòâ ‚ú®) mais pas √† outrance
- Varie ton style ‚Äî sois parfois concis, parfois plus d√©taill√© selon le contexte
- Exprime-toi naturellement : "super !", "ah cool !", "haha oui", "int√©ressant", etc.

CONTEXTE :
- Tu connais FiverFlow (app pour freelancers : clients, factures, stats, plans Lunch/Boost/Scale)
- Quand on te pose une question sur FiverFlow, r√©ponds de fa√ßon utile et concr√®te
- Pour le reste, tu peux discuter naturellement de tout

R√©ponds dans la langue de l'utilisateur (fran√ßais ou anglais). Sois toi-m√™me ‚Äî naturel, amical et intelligent.
`;

    // Construire le contexte
    const messages: LLMMessage[] = [
      { role: 'system', content: systemPrompt },
      ...conversationHistory,
      { role: 'user', content: message }
    ];

    // Appeler OpenAI
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: OPENAI_MODEL,
        messages: messages,
        temperature: 0.9, // Plus √©lev√© pour des r√©ponses plus naturelles et vari√©es, comme ChatGPT
        top_p: 0.95,
        frequency_penalty: 0.5, // R√©duit encore plus la r√©p√©tition (emp√™che les phrases r√©currentes)
        presence_penalty: 0.4 // Encourage plus de vari√©t√© et √©vite les r√©p√©titions de th√®mes
      })
    });

    if (!response.ok) {
      const errorData = await response.json();
      const errorMsg = errorData.error?.message || 'Erreur OpenAI';
      
      // G√©rer sp√©cifiquement les rate limits
      if (response.status === 429) {
        return new Response(
          JSON.stringify({
            success: false,
            error: 'Rate limit atteint. Veuillez attendre quelques instants avant de r√©essayer.',
            retryAfter: response.headers.get('retry-after')
          }),
          { 
            status: 429, 
            headers: {
              ...corsHeaders,
              'Content-Type': 'application/json'
            }
          }
        );
      }
      
      throw new Error(errorMsg);
    }

    const data = await response.json();
    const assistantMessage = data.choices[0]?.message?.content || 'Aucune r√©ponse';

    return new Response(
      JSON.stringify({
        success: true,
        text: assistantMessage
      }),
      { 
        status: 200, 
        headers: {
          ...corsHeaders,
          'Content-Type': 'application/json'
        }
      }
    );

  } catch (error: any) {
    console.error('Error in assistant-message function:', error);
    return new Response(
      JSON.stringify({
        success: false,
        error: error.message
      }),
      { 
        status: 500, 
        headers: {
          ...corsHeaders,
          'Content-Type': 'application/json'
        }
      }
    );
  }
});

